{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5eb334e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b019ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniLangScanner:\n",
    "    \n",
    "    def __init__(self, file_path):\n",
    "        \n",
    "        #Read Source Code from the File\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:  \n",
    "            self.source_code = file.read()\n",
    "            \n",
    "         #Creating List to store the Tokens   \n",
    "        self.tokens = []\n",
    "        \n",
    "        #Set of Minilang Keywords as given in Task\n",
    "        self.keywords = {'if', 'else', 'print', 'true', 'false'}\n",
    "        self.current_position = 0\n",
    "\n",
    "    def scan(self):\n",
    "        \n",
    "        #Tokenize the Minilang Scource Code\n",
    "        while self.current_position < len(self.source_code):\n",
    "            \n",
    "            #Ignoring the Whitespaces and Comments\n",
    "            self._skip_whitespace_and_comments()\n",
    "\n",
    "            #Reach the End of the File and Check\n",
    "            if self.current_position >= len(self.source_code):\n",
    "                break\n",
    "                \n",
    "            #Matching the types of Tokens to respective\n",
    "            if self._match_identifier():\n",
    "                continue\n",
    "            elif self._match_literal():\n",
    "                continue\n",
    "            elif self._match_operator():\n",
    "                continue\n",
    "                \n",
    "            #Condition for invalid Token    \n",
    "            else:\n",
    "                self._report_error(\"Invalid token\")\n",
    "\n",
    "        return self.tokens\n",
    "\n",
    "    \n",
    "    #Function for skipping white spaces and comment lines with // \n",
    "    def _skip_whitespace_and_comments(self):\n",
    "        \n",
    "        whitespace_and_comment_pattern = re.compile(r'\\s+|//.*')\n",
    "        match = whitespace_and_comment_pattern.match(self.source_code, self.current_position)\n",
    "        while match:\n",
    "            self.current_position = match.end()\n",
    "            match = whitespace_and_comment_pattern.match(self.source_code, self.current_position)\n",
    "\n",
    "            \n",
    "    #Function for Matching the Identifiers\n",
    "    def _match_identifier(self):\n",
    "        identifier_pattern = re.compile(r'[a-zA-Z][a-zA-Z0-9]*')\n",
    "        match = identifier_pattern.match(self.source_code, self.current_position)\n",
    "        \n",
    "        #If the string matched get it & Append for keywords and identifiers\n",
    "        if match:\n",
    "            lexeme = match.group()\n",
    "            if lexeme in self.keywords:\n",
    "                self.tokens.append((\"Keyword\", lexeme))\n",
    "            else:\n",
    "                self.tokens.append((\"Identifier\", lexeme))\n",
    "            self.current_position = match.end()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "    #Function for matching Literals\n",
    "    def _match_literal(self):\n",
    "        literal_pattern = re.compile(r'\\d+|true|false|\"([^\"]*)\"')\n",
    "        match = literal_pattern.match(self.source_code, self.current_position)\n",
    "        \n",
    "        #If matched get the string and Append for Literals of Int, Bool, String\n",
    "        if match:\n",
    "            lexeme = match.group()\n",
    "            if lexeme.isdigit():\n",
    "                self.tokens.append((\"Integer Literal\", int(lexeme)))\n",
    "            elif lexeme == 'true' or lexeme == 'false':\n",
    "                self.tokens.append((\"Boolean Literal\", lexeme == 'true'))\n",
    "            elif lexeme.startswith('\"') and lexeme.endswith('\"'):\n",
    "                self.tokens.append((\"String Literal\", lexeme[1:-1]))\n",
    "            self.current_position = match.end()\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    #Fucntion for Matching the Operators asked for in assignment (+, -, *, /, =, ==, != )\n",
    "    def _match_operator(self):\n",
    "        \n",
    "        operator_pattern = re.compile(r'==|!=|[=+\\-*/]')\n",
    "        match = operator_pattern.match(self.source_code, self.current_position)\n",
    "        \n",
    "        #If Matched get the string and append for Operator\n",
    "        if match:\n",
    "            lexeme = match.group()\n",
    "            self.tokens.append((\"Operator\", lexeme))\n",
    "            self.current_position = match.end()\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    #Fucntion for handling Lexical Errors\n",
    "    def _report_error(self, message):\n",
    "        error_position = min(self.current_position, len(self.source_code))\n",
    "        snippet = self.source_code[max(0, error_position - 10):min(len(self.source_code), error_position + 10)]\n",
    "        raise ValueError(f\"Lexical Error: {message} at position {error_position}\\n{snippet}\")\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e43cd86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tCASE 1\n",
      "\n",
      "Identifier: x\n",
      "Operator: =\n",
      "Integer Literal: 5\n",
      "Identifier: y\n",
      "Operator: =\n",
      "Integer Literal: 10\n",
      "Keyword: if\n",
      "Identifier: x\n",
      "Operator: ==\n",
      "Identifier: y\n",
      "Keyword: print\n",
      "String Literal: x is equal to y\n",
      "Keyword: else\n",
      "Keyword: print\n",
      "String Literal: x is not equal to y\n",
      "\n",
      "\n",
      "\tCASE 2\n",
      "\n",
      "Identifier: a\n",
      "Operator: =\n",
      "Integer Literal: 10\n",
      "Identifier: b\n",
      "Operator: =\n",
      "Integer Literal: 20\n",
      "Keyword: if\n",
      "Identifier: a\n",
      "Operator: !=\n",
      "Identifier: b\n",
      "Keyword: print\n",
      "String Literal: a is not equal to b\n",
      "Keyword: else\n",
      "Keyword: print\n",
      "String Literal: a is equal to b\n",
      "\n",
      "\n",
      "\tCASE 3\n",
      "\n",
      "Identifier: a\n",
      "Operator: =\n",
      "Keyword: true\n",
      "Identifier: b\n",
      "Operator: =\n",
      "Keyword: false\n",
      "Keyword: if\n",
      "Identifier: a\n",
      "Identifier: and\n",
      "Identifier: b\n",
      "Keyword: print\n",
      "String Literal: Both a and b are true\n",
      "Keyword: else\n",
      "Keyword: print\n",
      "String Literal: At least one of a and b is false\n",
      "\n",
      "\n",
      "\tCASE 4\n",
      "\n",
      "Lexical Error: Invalid token at position 132\n",
      "er\n",
      "invalid_identifie\n",
      "\n",
      "\n",
      "\tEDGE CASE 1\n",
      "\n",
      "\n",
      "\n",
      "\tEDGE CASE 2\n",
      "\n",
      "\n",
      "\n",
      "\tEDGE CASE 3\n",
      "\n",
      "\n",
      "\n",
      "\tEDGE CASE 4\n",
      "\n",
      "Identifier: a1234567890123456789012345678901234567890\n",
      "Operator: =\n",
      "Integer Literal: 42\n"
     ]
    }
   ],
   "source": [
    "def process_case(file_path):\n",
    "    try:\n",
    "        scanner = MiniLangScanner(file_path)\n",
    "        tokens = scanner.scan()\n",
    "\n",
    "        for token_type, lexeme in tokens:\n",
    "            print(f\"{token_type}: {lexeme}\")\n",
    "\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Call the function for each case study\n",
    "    \n",
    "    #If else case\n",
    "    print(\"\\n\\tCASE 1\\n\")\n",
    "    process_case('case1.txt')\n",
    "    \n",
    "    #Case for != operator\n",
    "    print(\"\\n\\n\\tCASE 2\\n\")\n",
    "    process_case('case2.txt')\n",
    "    \n",
    "    \n",
    "    #Case for Boolean\n",
    "    print(\"\\n\\n\\tCASE 3\\n\")\n",
    "    process_case('case3.txt')\n",
    "\n",
    "    #Case to check Lexical Error\n",
    "    print(\"\\n\\n\\tCASE 4\\n\")\n",
    "    process_case('case4.txt')\n",
    "    \n",
    "     #Edge Case to check an empty file\n",
    "    print(\"\\n\\n\\tEDGE CASE 1\\n\")\n",
    "    process_case('edge case 1.txt')\n",
    "\n",
    "    \n",
    "     #Edge Case to check aa file with white spaces only\n",
    "    print(\"\\n\\n\\tEDGE CASE 2\\n\")\n",
    "    process_case('edge case 2.txt')\n",
    "\n",
    "    \n",
    "     #Edge Case to check a file with comments only\n",
    "    print(\"\\n\\n\\tEDGE CASE 3\\n\")\n",
    "    process_case('edge case 3.txt')\n",
    "\n",
    "    \n",
    "     #Edge Case to check a file with Long Identifiers\n",
    "    print(\"\\n\\n\\tEDGE CASE 4\\n\")\n",
    "    process_case('edge case 4.txt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374cd00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
